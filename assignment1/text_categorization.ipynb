{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=None)\n",
    "X, y = newsgroups.data, newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert data to TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       151\n",
      "           1       0.88      0.84      0.86       202\n",
      "           2       0.86      0.85      0.85       195\n",
      "           3       0.64      0.85      0.73       183\n",
      "           4       0.94      0.87      0.90       205\n",
      "           5       0.95      0.85      0.90       215\n",
      "           6       0.93      0.72      0.81       193\n",
      "           7       0.91      0.94      0.92       196\n",
      "           8       0.89      0.95      0.92       168\n",
      "           9       0.95      0.95      0.95       211\n",
      "          10       0.90      0.99      0.94       198\n",
      "          11       0.91      0.97      0.93       201\n",
      "          12       0.92      0.82      0.86       202\n",
      "          13       0.97      0.93      0.95       194\n",
      "          14       0.88      0.99      0.93       189\n",
      "          15       0.71      0.99      0.83       202\n",
      "          16       0.82      0.97      0.89       188\n",
      "          17       0.95      0.99      0.97       182\n",
      "          18       0.96      0.75      0.84       159\n",
      "          19       1.00      0.31      0.47       136\n",
      "\n",
      "    accuracy                           0.88      3770\n",
      "   macro avg       0.89      0.87      0.87      3770\n",
      "weighted avg       0.89      0.88      0.87      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(\"Naive Bayes Classifier Report:\\n\", classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       151\n",
      "           1       0.79      0.87      0.83       202\n",
      "           2       0.83      0.82      0.83       195\n",
      "           3       0.72      0.76      0.74       183\n",
      "           4       0.90      0.85      0.88       205\n",
      "           5       0.89      0.86      0.87       215\n",
      "           6       0.84      0.83      0.83       193\n",
      "           7       0.91      0.94      0.93       196\n",
      "           8       0.97      0.93      0.95       168\n",
      "           9       0.97      0.97      0.97       211\n",
      "          10       0.96      0.97      0.97       198\n",
      "          11       0.99      0.95      0.97       201\n",
      "          12       0.85      0.87      0.86       202\n",
      "          13       0.95      0.96      0.95       194\n",
      "          14       0.91      0.98      0.94       189\n",
      "          15       0.92      0.98      0.95       202\n",
      "          16       0.94      0.93      0.93       188\n",
      "          17       0.99      0.98      0.99       182\n",
      "          18       0.93      0.86      0.89       159\n",
      "          19       0.89      0.73      0.80       136\n",
      "\n",
      "    accuracy                           0.90      3770\n",
      "   macro avg       0.90      0.90      0.90      3770\n",
      "weighted avg       0.90      0.90      0.90      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Logistic Regression Classifier Report:\\n\", classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Classifier Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       151\n",
      "           1       0.83      0.91      0.87       202\n",
      "           2       0.91      0.89      0.90       195\n",
      "           3       0.79      0.80      0.80       183\n",
      "           4       0.90      0.92      0.91       205\n",
      "           5       0.92      0.91      0.91       215\n",
      "           6       0.88      0.85      0.86       193\n",
      "           7       0.93      0.94      0.93       196\n",
      "           8       0.96      0.95      0.96       168\n",
      "           9       0.99      1.00      0.99       211\n",
      "          10       0.97      0.99      0.98       198\n",
      "          11       0.98      0.98      0.98       201\n",
      "          12       0.93      0.87      0.90       202\n",
      "          13       0.95      0.96      0.95       194\n",
      "          14       0.96      0.98      0.97       189\n",
      "          15       0.96      0.98      0.97       202\n",
      "          16       0.95      0.95      0.95       188\n",
      "          17       0.99      0.99      0.99       182\n",
      "          18       0.96      0.91      0.93       159\n",
      "          19       0.92      0.88      0.90       136\n",
      "\n",
      "    accuracy                           0.93      3770\n",
      "   macro avg       0.93      0.93      0.93      3770\n",
      "weighted avg       0.93      0.93      0.93      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, y_train)\n",
    "y_pred_svc = linear_svc.predict(X_test)\n",
    "print(\"Linear SVC Classifier Report:\\n\", classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 2142075 stored elements and shape (18846, 173451)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question3\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# Count \n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "X_counts = count_vect.fit_transform(X)\n",
    "X_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 2142075 stored elements and shape (18846, 173451)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF \n",
    "tf_vect = TfidfVectorizer(stop_words='english', use_idf=False, norm='l2')\n",
    "X_tf = tf_vect.fit_transform(X)\n",
    "X_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 2142075 stored elements and shape (18846, 173451)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', use_idf=True, norm='l2')\n",
    "X_tfidf = tfidf_vect.fit_transform(X)\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts, X_test_counts, y_train, y_test = train_test_split(X_counts, y, test_size=0.3, random_state=42)\n",
    "X_train_tf, X_test_tf, _, _ = train_test_split(X_tf, y, test_size=0.3, random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with Counts:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       236\n",
      "           1       0.65      0.92      0.76       287\n",
      "           2       0.98      0.43      0.60       290\n",
      "           3       0.64      0.87      0.74       285\n",
      "           4       0.93      0.83      0.88       312\n",
      "           5       0.86      0.83      0.85       308\n",
      "           6       0.90      0.74      0.81       276\n",
      "           7       0.92      0.93      0.93       304\n",
      "           8       0.97      0.95      0.96       279\n",
      "           9       0.97      0.95      0.96       308\n",
      "          10       0.95      0.98      0.96       309\n",
      "          11       0.89      0.97      0.93       290\n",
      "          12       0.88      0.83      0.86       304\n",
      "          13       0.96      0.93      0.94       300\n",
      "          14       0.91      0.98      0.94       297\n",
      "          15       0.85      0.99      0.91       292\n",
      "          16       0.89      0.94      0.92       270\n",
      "          17       0.95      0.99      0.97       272\n",
      "          18       0.85      0.89      0.87       239\n",
      "          19       0.94      0.54      0.68       196\n",
      "\n",
      "    accuracy                           0.87      5654\n",
      "   macro avg       0.89      0.87      0.87      5654\n",
      "weighted avg       0.89      0.87      0.87      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes counts\n",
    "nb_counts = MultinomialNB()\n",
    "nb_counts.fit(X_train_counts, y_train)\n",
    "y_pred_counts = nb_counts.predict(X_test_counts)\n",
    "print(\"Naive Bayes with Counts:\\n\", classification_report(y_test, y_pred_counts))\n",
    "\n",
    "# TF\n",
    "nb_tf = MultinomialNB()\n",
    "nb_tf.fit(X_train_tf, y_train)\n",
    "y_pred_tf = nb_tf.predict(X_test_tf)\n",
    "\n",
    "# TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with TF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80       236\n",
      "           1       0.77      0.81      0.79       287\n",
      "           2       0.80      0.83      0.82       290\n",
      "           3       0.65      0.85      0.74       285\n",
      "           4       0.95      0.75      0.84       312\n",
      "           5       0.97      0.81      0.88       308\n",
      "           6       0.85      0.77      0.81       276\n",
      "           7       0.91      0.92      0.91       304\n",
      "           8       0.86      0.95      0.90       279\n",
      "           9       0.94      0.94      0.94       308\n",
      "          10       0.88      0.97      0.93       309\n",
      "          11       0.83      0.97      0.89       290\n",
      "          12       0.90      0.76      0.82       304\n",
      "          13       0.96      0.88      0.92       300\n",
      "          14       0.87      0.98      0.92       297\n",
      "          15       0.62      0.99      0.77       292\n",
      "          16       0.75      0.95      0.84       270\n",
      "          17       0.91      0.98      0.94       272\n",
      "          18       0.99      0.55      0.71       239\n",
      "          19       0.97      0.14      0.25       196\n",
      "\n",
      "    accuracy                           0.84      5654\n",
      "   macro avg       0.86      0.83      0.82      5654\n",
      "weighted avg       0.86      0.84      0.83      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes with TF:\\n\", classification_report(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       236\n",
      "           1       0.84      0.84      0.84       287\n",
      "           2       0.86      0.84      0.85       290\n",
      "           3       0.67      0.85      0.75       285\n",
      "           4       0.95      0.83      0.88       312\n",
      "           5       0.96      0.83      0.89       308\n",
      "           6       0.87      0.77      0.82       276\n",
      "           7       0.93      0.91      0.92       304\n",
      "           8       0.92      0.96      0.94       279\n",
      "           9       0.95      0.96      0.96       308\n",
      "          10       0.91      0.98      0.94       309\n",
      "          11       0.86      0.98      0.91       290\n",
      "          12       0.92      0.80      0.86       304\n",
      "          13       0.97      0.91      0.94       300\n",
      "          14       0.90      0.97      0.93       297\n",
      "          15       0.68      0.99      0.81       292\n",
      "          16       0.79      0.97      0.87       270\n",
      "          17       0.93      0.99      0.96       272\n",
      "          18       0.98      0.71      0.82       239\n",
      "          19       0.98      0.27      0.42       196\n",
      "\n",
      "    accuracy                           0.87      5654\n",
      "   macro avg       0.89      0.86      0.86      5654\n",
      "weighted avg       0.89      0.87      0.87      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes with TF-IDF:\\n\", classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Counts:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       236\n",
      "           1       0.77      0.83      0.80       287\n",
      "           2       0.84      0.82      0.83       290\n",
      "           3       0.74      0.74      0.74       285\n",
      "           4       0.85      0.86      0.85       312\n",
      "           5       0.88      0.84      0.86       308\n",
      "           6       0.82      0.84      0.83       276\n",
      "           7       0.90      0.91      0.90       304\n",
      "           8       0.97      0.94      0.95       279\n",
      "           9       0.95      0.96      0.95       308\n",
      "          10       0.96      0.96      0.96       309\n",
      "          11       0.98      0.95      0.96       290\n",
      "          12       0.81      0.80      0.80       304\n",
      "          13       0.93      0.96      0.94       300\n",
      "          14       0.94      0.93      0.93       297\n",
      "          15       0.91      0.98      0.94       292\n",
      "          16       0.92      0.94      0.93       270\n",
      "          17       0.99      0.96      0.98       272\n",
      "          18       0.91      0.86      0.89       239\n",
      "          19       0.86      0.82      0.84       196\n",
      "\n",
      "    accuracy                           0.89      5654\n",
      "   macro avg       0.89      0.89      0.89      5654\n",
      "weighted avg       0.89      0.89      0.89      5654\n",
      "\n",
      "Logistic Regression with TF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       236\n",
      "           1       0.72      0.80      0.76       287\n",
      "           2       0.79      0.81      0.80       290\n",
      "           3       0.72      0.70      0.71       285\n",
      "           4       0.86      0.82      0.84       312\n",
      "           5       0.83      0.81      0.82       308\n",
      "           6       0.77      0.82      0.79       276\n",
      "           7       0.88      0.90      0.89       304\n",
      "           8       0.96      0.92      0.94       279\n",
      "           9       0.91      0.94      0.93       308\n",
      "          10       0.94      0.95      0.95       309\n",
      "          11       0.98      0.93      0.95       290\n",
      "          12       0.81      0.80      0.81       304\n",
      "          13       0.91      0.92      0.92       300\n",
      "          14       0.91      0.93      0.92       297\n",
      "          15       0.87      0.98      0.92       292\n",
      "          16       0.91      0.91      0.91       270\n",
      "          17       0.99      0.96      0.97       272\n",
      "          18       0.91      0.85      0.87       239\n",
      "          19       0.89      0.65      0.75       196\n",
      "\n",
      "    accuracy                           0.87      5654\n",
      "   macro avg       0.87      0.87      0.87      5654\n",
      "weighted avg       0.87      0.87      0.87      5654\n",
      "\n",
      "Logistic Regression with TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       236\n",
      "           1       0.78      0.87      0.83       287\n",
      "           2       0.84      0.85      0.85       290\n",
      "           3       0.76      0.78      0.77       285\n",
      "           4       0.90      0.87      0.89       312\n",
      "           5       0.89      0.86      0.87       308\n",
      "           6       0.81      0.86      0.83       276\n",
      "           7       0.92      0.91      0.92       304\n",
      "           8       0.96      0.95      0.95       279\n",
      "           9       0.95      0.96      0.96       308\n",
      "          10       0.96      0.97      0.96       309\n",
      "          11       0.98      0.95      0.96       290\n",
      "          12       0.85      0.85      0.85       304\n",
      "          13       0.95      0.94      0.95       300\n",
      "          14       0.93      0.96      0.94       297\n",
      "          15       0.89      0.98      0.93       292\n",
      "          16       0.93      0.94      0.93       270\n",
      "          17       0.99      0.98      0.99       272\n",
      "          18       0.93      0.87      0.90       239\n",
      "          19       0.89      0.68      0.77       196\n",
      "\n",
      "    accuracy                           0.90      5654\n",
      "   macro avg       0.90      0.90      0.90      5654\n",
      "weighted avg       0.90      0.90      0.90      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression \n",
    "lr_counts = LogisticRegression(max_iter=1000)\n",
    "lr_counts.fit(X_train_counts, y_train)\n",
    "y_pred_counts = lr_counts.predict(X_test_counts)\n",
    "\n",
    "lr_tf = LogisticRegression(max_iter=1000)\n",
    "lr_tf.fit(X_train_tf, y_train)\n",
    "y_pred_tf = lr_tf.predict(X_test_tf)\n",
    "\n",
    "lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = lr_tfidf.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Counts:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       236\n",
      "           1       0.77      0.83      0.80       287\n",
      "           2       0.84      0.82      0.83       290\n",
      "           3       0.74      0.74      0.74       285\n",
      "           4       0.85      0.86      0.85       312\n",
      "           5       0.88      0.84      0.86       308\n",
      "           6       0.82      0.84      0.83       276\n",
      "           7       0.90      0.91      0.90       304\n",
      "           8       0.97      0.94      0.95       279\n",
      "           9       0.95      0.96      0.95       308\n",
      "          10       0.96      0.96      0.96       309\n",
      "          11       0.98      0.95      0.96       290\n",
      "          12       0.81      0.80      0.80       304\n",
      "          13       0.93      0.96      0.94       300\n",
      "          14       0.94      0.93      0.93       297\n",
      "          15       0.91      0.98      0.94       292\n",
      "          16       0.92      0.94      0.93       270\n",
      "          17       0.99      0.96      0.98       272\n",
      "          18       0.91      0.86      0.89       239\n",
      "          19       0.86      0.82      0.84       196\n",
      "\n",
      "    accuracy                           0.89      5654\n",
      "   macro avg       0.89      0.89      0.89      5654\n",
      "weighted avg       0.89      0.89      0.89      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with Counts:\\n\", classification_report(y_test, y_pred_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with TF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       236\n",
      "           1       0.72      0.80      0.76       287\n",
      "           2       0.79      0.81      0.80       290\n",
      "           3       0.72      0.70      0.71       285\n",
      "           4       0.86      0.82      0.84       312\n",
      "           5       0.83      0.81      0.82       308\n",
      "           6       0.77      0.82      0.79       276\n",
      "           7       0.88      0.90      0.89       304\n",
      "           8       0.96      0.92      0.94       279\n",
      "           9       0.91      0.94      0.93       308\n",
      "          10       0.94      0.95      0.95       309\n",
      "          11       0.98      0.93      0.95       290\n",
      "          12       0.81      0.80      0.81       304\n",
      "          13       0.91      0.92      0.92       300\n",
      "          14       0.91      0.93      0.92       297\n",
      "          15       0.87      0.98      0.92       292\n",
      "          16       0.91      0.91      0.91       270\n",
      "          17       0.99      0.96      0.97       272\n",
      "          18       0.91      0.85      0.87       239\n",
      "          19       0.89      0.65      0.75       196\n",
      "\n",
      "    accuracy                           0.87      5654\n",
      "   macro avg       0.87      0.87      0.87      5654\n",
      "weighted avg       0.87      0.87      0.87      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with TF:\\n\", classification_report(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MJM\\OneDrive\\桌面\\text mining\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "linear_svc_counts = LinearSVC()\n",
    "linear_svc_counts.fit(X_train_counts, y_train)\n",
    "y_pred_counts = linear_svc_counts.predict(X_test_counts)\n",
    "\n",
    "linear_svc_tf = LinearSVC()\n",
    "linear_svc_tf.fit(X_train_tf, y_train)\n",
    "y_pred_tf = linear_svc_tf.predict(X_test_tf)\n",
    "\n",
    "linear_svc_tfidf = LinearSVC()\n",
    "linear_svc_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = linear_svc_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC with Counts:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       236\n",
      "           1       0.78      0.80      0.79       287\n",
      "           2       0.85      0.83      0.84       290\n",
      "           3       0.73      0.74      0.74       285\n",
      "           4       0.84      0.83      0.84       312\n",
      "           5       0.89      0.84      0.86       308\n",
      "           6       0.82      0.84      0.83       276\n",
      "           7       0.92      0.91      0.91       304\n",
      "           8       0.96      0.97      0.96       279\n",
      "           9       0.94      0.96      0.95       308\n",
      "          10       0.97      0.97      0.97       309\n",
      "          11       0.98      0.97      0.97       290\n",
      "          12       0.82      0.77      0.80       304\n",
      "          13       0.90      0.95      0.92       300\n",
      "          14       0.94      0.95      0.94       297\n",
      "          15       0.88      0.97      0.92       292\n",
      "          16       0.90      0.95      0.93       270\n",
      "          17       0.99      0.96      0.97       272\n",
      "          18       0.92      0.87      0.89       239\n",
      "          19       0.87      0.80      0.83       196\n",
      "\n",
      "    accuracy                           0.89      5654\n",
      "   macro avg       0.89      0.89      0.89      5654\n",
      "weighted avg       0.89      0.89      0.89      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVC with Counts:\\n\", classification_report(y_test, y_pred_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC with TF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       236\n",
      "           1       0.82      0.85      0.83       287\n",
      "           2       0.86      0.88      0.87       290\n",
      "           3       0.81      0.78      0.79       285\n",
      "           4       0.88      0.90      0.89       312\n",
      "           5       0.91      0.87      0.89       308\n",
      "           6       0.85      0.87      0.86       276\n",
      "           7       0.92      0.92      0.92       304\n",
      "           8       0.97      0.96      0.96       279\n",
      "           9       0.95      0.98      0.97       308\n",
      "          10       0.97      0.98      0.98       309\n",
      "          11       0.98      0.97      0.97       290\n",
      "          12       0.90      0.83      0.86       304\n",
      "          13       0.97      0.97      0.97       300\n",
      "          14       0.94      0.97      0.96       297\n",
      "          15       0.92      0.98      0.95       292\n",
      "          16       0.92      0.96      0.94       270\n",
      "          17       0.98      0.99      0.98       272\n",
      "          18       0.94      0.89      0.92       239\n",
      "          19       0.89      0.82      0.85       196\n",
      "\n",
      "    accuracy                           0.91      5654\n",
      "   macro avg       0.91      0.91      0.91      5654\n",
      "weighted avg       0.91      0.91      0.91      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVC with TF:\\n\", classification_report(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC with TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       236\n",
      "           1       0.83      0.87      0.85       287\n",
      "           2       0.89      0.89      0.89       290\n",
      "           3       0.81      0.79      0.80       285\n",
      "           4       0.90      0.91      0.90       312\n",
      "           5       0.92      0.89      0.91       308\n",
      "           6       0.85      0.87      0.86       276\n",
      "           7       0.95      0.93      0.94       304\n",
      "           8       0.97      0.96      0.97       279\n",
      "           9       0.97      0.99      0.98       308\n",
      "          10       0.97      0.98      0.97       309\n",
      "          11       0.98      0.98      0.98       290\n",
      "          12       0.90      0.86      0.88       304\n",
      "          13       0.96      0.97      0.96       300\n",
      "          14       0.95      0.97      0.96       297\n",
      "          15       0.95      0.99      0.97       292\n",
      "          16       0.94      0.96      0.95       270\n",
      "          17       0.99      0.99      0.99       272\n",
      "          18       0.94      0.91      0.93       239\n",
      "          19       0.93      0.85      0.89       196\n",
      "\n",
      "    accuracy                           0.93      5654\n",
      "   macro avg       0.93      0.92      0.93      5654\n",
      "weighted avg       0.93      0.93      0.93      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVC with TF-IDF:\\n\", classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       236\n",
      "           1       0.77      0.77      0.77       287\n",
      "           2       0.83      0.82      0.82       290\n",
      "           3       0.72      0.73      0.72       285\n",
      "           4       0.85      0.83      0.84       312\n",
      "           5       0.86      0.86      0.86       308\n",
      "           6       0.82      0.84      0.83       276\n",
      "           7       0.90      0.91      0.90       304\n",
      "           8       0.94      0.95      0.94       279\n",
      "           9       0.93      0.95      0.94       308\n",
      "          10       0.96      0.97      0.97       309\n",
      "          11       0.97      0.96      0.96       290\n",
      "          12       0.82      0.78      0.80       304\n",
      "          13       0.93      0.95      0.94       300\n",
      "          14       0.92      0.95      0.94       297\n",
      "          15       0.89      0.96      0.92       292\n",
      "          16       0.91      0.93      0.92       270\n",
      "          17       0.98      0.96      0.97       272\n",
      "          18       0.92      0.85      0.89       239\n",
      "          19       0.87      0.76      0.81       196\n",
      "\n",
      "    accuracy                           0.88      5654\n",
      "   macro avg       0.88      0.88      0.88      5654\n",
      "weighted avg       0.88      0.88      0.88      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#question4\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size=0.3, random_state=42)\n",
    "\n",
    "def experiment_with_vectorizer(vectorizer):\n",
    "  \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LinearSVC())\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english', analyzer='word', ngram_range=(1, 1), max_features=5000)\n",
    "experiment_with_vectorizer(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       236\n",
      "           1       0.72      0.76      0.74       287\n",
      "           2       0.79      0.82      0.81       290\n",
      "           3       0.73      0.73      0.73       285\n",
      "           4       0.83      0.78      0.80       312\n",
      "           5       0.85      0.86      0.85       308\n",
      "           6       0.81      0.85      0.83       276\n",
      "           7       0.88      0.88      0.88       304\n",
      "           8       0.94      0.94      0.94       279\n",
      "           9       0.92      0.92      0.92       308\n",
      "          10       0.95      0.97      0.96       309\n",
      "          11       0.96      0.93      0.95       290\n",
      "          12       0.79      0.77      0.78       304\n",
      "          13       0.92      0.91      0.91       300\n",
      "          14       0.93      0.92      0.93       297\n",
      "          15       0.88      0.95      0.91       292\n",
      "          16       0.89      0.93      0.91       270\n",
      "          17       0.97      0.95      0.96       272\n",
      "          18       0.86      0.85      0.85       239\n",
      "          19       0.83      0.70      0.76       196\n",
      "\n",
      "    accuracy                           0.87      5654\n",
      "   macro avg       0.87      0.86      0.87      5654\n",
      "weighted avg       0.87      0.87      0.87      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(lowercase=False, stop_words=None, analyzer='word', ngram_range=(1, 1), max_features=5000)\n",
    "experiment_with_vectorizer(vectorizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       236\n",
      "           1       0.51      0.54      0.52       287\n",
      "           2       0.69      0.62      0.66       290\n",
      "           3       0.56      0.56      0.56       285\n",
      "           4       0.68      0.62      0.65       312\n",
      "           5       0.60      0.60      0.60       308\n",
      "           6       0.66      0.70      0.68       276\n",
      "           7       0.67      0.71      0.69       304\n",
      "           8       0.74      0.77      0.76       279\n",
      "           9       0.76      0.80      0.78       308\n",
      "          10       0.76      0.86      0.81       309\n",
      "          11       0.93      0.87      0.90       290\n",
      "          12       0.63      0.58      0.60       304\n",
      "          13       0.73      0.69      0.71       300\n",
      "          14       0.84      0.84      0.84       297\n",
      "          15       0.85      0.87      0.86       292\n",
      "          16       0.84      0.89      0.86       270\n",
      "          17       0.93      0.93      0.93       272\n",
      "          18       0.89      0.80      0.84       239\n",
      "          19       0.80      0.72      0.76       196\n",
      "\n",
      "    accuracy                           0.74      5654\n",
      "   macro avg       0.75      0.74      0.74      5654\n",
      "weighted avg       0.74      0.74      0.74      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer3 = CountVectorizer(lowercase=True, stop_words='english', analyzer='word', ngram_range=(2, 2), max_features=5000)\n",
    "experiment_with_vectorizer(vectorizer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MJM\\OneDrive\\桌面\\text mining\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:543: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       236\n",
      "           1       0.76      0.77      0.77       287\n",
      "           2       0.78      0.83      0.80       290\n",
      "           3       0.73      0.70      0.71       285\n",
      "           4       0.85      0.82      0.83       312\n",
      "           5       0.90      0.88      0.89       308\n",
      "           6       0.71      0.79      0.75       276\n",
      "           7       0.88      0.86      0.87       304\n",
      "           8       0.93      0.93      0.93       279\n",
      "           9       0.94      0.91      0.92       308\n",
      "          10       0.90      0.95      0.92       309\n",
      "          11       0.96      0.93      0.95       290\n",
      "          12       0.81      0.76      0.78       304\n",
      "          13       0.88      0.90      0.89       300\n",
      "          14       0.92      0.95      0.94       297\n",
      "          15       0.86      0.96      0.91       292\n",
      "          16       0.89      0.93      0.91       270\n",
      "          17       0.96      0.96      0.96       272\n",
      "          18       0.91      0.85      0.88       239\n",
      "          19       0.85      0.66      0.74       196\n",
      "\n",
      "    accuracy                           0.86      5654\n",
      "   macro avg       0.86      0.86      0.86      5654\n",
      "weighted avg       0.86      0.86      0.86      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer4 = CountVectorizer(lowercase=True, stop_words='english', analyzer='char', ngram_range=(3, 3), max_features=5000)\n",
    "experiment_with_vectorizer(vectorizer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       236\n",
      "           1       0.80      0.83      0.81       287\n",
      "           2       0.86      0.83      0.84       290\n",
      "           3       0.76      0.75      0.76       285\n",
      "           4       0.87      0.86      0.86       312\n",
      "           5       0.88      0.86      0.87       308\n",
      "           6       0.83      0.84      0.84       276\n",
      "           7       0.92      0.93      0.93       304\n",
      "           8       0.95      0.96      0.95       279\n",
      "           9       0.97      0.97      0.97       308\n",
      "          10       0.97      0.99      0.98       309\n",
      "          11       0.97      0.96      0.97       290\n",
      "          12       0.87      0.82      0.84       304\n",
      "          13       0.93      0.96      0.95       300\n",
      "          14       0.94      0.97      0.95       297\n",
      "          15       0.92      0.97      0.94       292\n",
      "          16       0.91      0.95      0.93       270\n",
      "          17       0.98      0.98      0.98       272\n",
      "          18       0.92      0.88      0.90       239\n",
      "          19       0.90      0.81      0.85       196\n",
      "\n",
      "    accuracy                           0.90      5654\n",
      "   macro avg       0.90      0.90      0.90      5654\n",
      "weighted avg       0.90      0.90      0.90      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer5 = CountVectorizer(lowercase=True, stop_words=None, analyzer='word', ngram_range=(1, 1), max_features=10000)\n",
    "experiment_with_vectorizer(vectorizer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
